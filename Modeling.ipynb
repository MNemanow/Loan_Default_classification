{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "notebook_start = time.time()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (confusion_matrix, plot_confusion_matrix, plot_roc_curve, \n",
    "                             accuracy_score, recall_score, precision_score, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 482754 entries, 0 to 482753\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   term              482754 non-null  object \n",
      " 1   int_rate          482754 non-null  float64\n",
      " 2   grade             482754 non-null  object \n",
      " 3   dti               482754 non-null  float64\n",
      " 4   loan_status       482754 non-null  int64  \n",
      " 5   emp_length        482754 non-null  object \n",
      " 6   loan_amnt         482754 non-null  float64\n",
      " 7   annual_inc        482754 non-null  float64\n",
      " 8   application_type  482754 non-null  object \n",
      " 9   home_ownership    482754 non-null  object \n",
      " 10  date              482754 non-null  object \n",
      " 11  zip_code          482754 non-null  object \n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 44.2+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>grade</th>\n",
       "      <th>dti</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>application_type</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>date</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36 months</td>\n",
       "      <td>11.22</td>\n",
       "      <td>B</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0</td>\n",
       "      <td>7 years</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>201xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36 months</td>\n",
       "      <td>9.17</td>\n",
       "      <td>B</td>\n",
       "      <td>20.30</td>\n",
       "      <td>0</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>82400.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>146xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36 months</td>\n",
       "      <td>5.32</td>\n",
       "      <td>A</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0</td>\n",
       "      <td>9 years</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>OWN</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>208xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36 months</td>\n",
       "      <td>10.78</td>\n",
       "      <td>B</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>6 years</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>908xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36 months</td>\n",
       "      <td>12.88</td>\n",
       "      <td>C</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>3725.0</td>\n",
       "      <td>16800.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>294xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482749</th>\n",
       "      <td>36 months</td>\n",
       "      <td>14.47</td>\n",
       "      <td>C</td>\n",
       "      <td>23.76</td>\n",
       "      <td>0</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>7450.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>483xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482750</th>\n",
       "      <td>36 months</td>\n",
       "      <td>12.98</td>\n",
       "      <td>B</td>\n",
       "      <td>26.50</td>\n",
       "      <td>0</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>917xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482751</th>\n",
       "      <td>36 months</td>\n",
       "      <td>7.02</td>\n",
       "      <td>A</td>\n",
       "      <td>16.38</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>97000.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>801xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482752</th>\n",
       "      <td>36 months</td>\n",
       "      <td>15.02</td>\n",
       "      <td>C</td>\n",
       "      <td>11.64</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>Individual</td>\n",
       "      <td>OWN</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>452xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482753</th>\n",
       "      <td>60 months</td>\n",
       "      <td>19.92</td>\n",
       "      <td>D</td>\n",
       "      <td>35.49</td>\n",
       "      <td>0</td>\n",
       "      <td>2 years</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Joint App</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>117xx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482754 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              term  int_rate grade    dti  loan_status emp_length  loan_amnt  \\\n",
       "0        36 months     11.22     B   3.10            0    7 years     5000.0   \n",
       "1        36 months      9.17     B  20.30            0  10+ years    35000.0   \n",
       "2        36 months      5.32     A   7.43            0    9 years    20000.0   \n",
       "3        36 months     10.78     B   2.75            0    6 years     6000.0   \n",
       "4        36 months     12.88     C   8.07            1   < 1 year     3725.0   \n",
       "...            ...       ...   ...    ...          ...        ...        ...   \n",
       "482749   36 months     14.47     C  23.76            0  10+ years     7450.0   \n",
       "482750   36 months     12.98     B  26.50            0  10+ years     9600.0   \n",
       "482751   36 months      7.02     A  16.38            0   < 1 year    20000.0   \n",
       "482752   36 months     15.02     C  11.64            0   < 1 year    10000.0   \n",
       "482753   60 months     19.92     D  35.49            0    2 years    10400.0   \n",
       "\n",
       "        annual_inc application_type home_ownership        date zip_code  \n",
       "0          65000.0       Individual       MORTGAGE  2016-01-01    201xx  \n",
       "1          82400.0       Individual       MORTGAGE  2016-01-01    146xx  \n",
       "2         200000.0       Individual            OWN  2016-01-01    208xx  \n",
       "3          85000.0       Individual           RENT  2016-01-01    908xx  \n",
       "4          16800.0       Individual           RENT  2016-01-01    294xx  \n",
       "...            ...              ...            ...         ...      ...  \n",
       "482749     76000.0       Individual       MORTGAGE  2018-12-01    483xx  \n",
       "482750     75000.0       Individual           RENT  2018-12-01    917xx  \n",
       "482751     97000.0       Individual           RENT  2018-12-01    801xx  \n",
       "482752     66000.0       Individual            OWN  2018-12-01    452xx  \n",
       "482753     40000.0        Joint App           RENT  2018-12-01    117xx  \n",
       "\n",
       "[482754 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "# download a dataset with a description of each column\n",
    "feat_def = pd.read_excel('https://resources.lendingclub.com/LCDataDictionary.xlsx')\n",
    "\n",
    "accepted_df = pd.read_csv('data/accepted_16_to_18.csv')\n",
    "print(accepted_df.info())\n",
    "accepted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned in the cleaning and eda notebook, I am going to focus on predicting the loans with high interest. But first I'll try to predict on all the loans.\n",
    "\n",
    "I will scale the numerical data, and use a label encoder to put the categorical features in numeric form so the model can handle them. I will scale after the train test split to avoid any leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>grade</th>\n",
       "      <th>dti</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>application_type</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>date</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11.22</td>\n",
       "      <td>1</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>201xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9.17</td>\n",
       "      <td>1</td>\n",
       "      <td>20.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>82400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>146xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5.32</td>\n",
       "      <td>0</td>\n",
       "      <td>7.43</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>208xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10.78</td>\n",
       "      <td>1</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>908xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12.88</td>\n",
       "      <td>2</td>\n",
       "      <td>8.07</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3725.0</td>\n",
       "      <td>16800.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>294xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482749</th>\n",
       "      <td>0</td>\n",
       "      <td>14.47</td>\n",
       "      <td>2</td>\n",
       "      <td>23.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7450.0</td>\n",
       "      <td>76000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>483xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482750</th>\n",
       "      <td>0</td>\n",
       "      <td>12.98</td>\n",
       "      <td>1</td>\n",
       "      <td>26.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>917xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482751</th>\n",
       "      <td>0</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0</td>\n",
       "      <td>16.38</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>97000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>801xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482752</th>\n",
       "      <td>0</td>\n",
       "      <td>15.02</td>\n",
       "      <td>2</td>\n",
       "      <td>11.64</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>452xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482753</th>\n",
       "      <td>1</td>\n",
       "      <td>19.92</td>\n",
       "      <td>3</td>\n",
       "      <td>35.49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10400.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>117xx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>482754 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        term  int_rate  grade    dti  loan_status  emp_length  loan_amnt  \\\n",
       "0          0     11.22      1   3.10            0           7     5000.0   \n",
       "1          0      9.17      1  20.30            0           1    35000.0   \n",
       "2          0      5.32      0   7.43            0           9    20000.0   \n",
       "3          0     10.78      1   2.75            0           6     6000.0   \n",
       "4          0     12.88      2   8.07            1          10     3725.0   \n",
       "...      ...       ...    ...    ...          ...         ...        ...   \n",
       "482749     0     14.47      2  23.76            0           1     7450.0   \n",
       "482750     0     12.98      1  26.50            0           1     9600.0   \n",
       "482751     0      7.02      0  16.38            0          10    20000.0   \n",
       "482752     0     15.02      2  11.64            0          10    10000.0   \n",
       "482753     1     19.92      3  35.49            0           2    10400.0   \n",
       "\n",
       "        annual_inc  application_type  home_ownership        date zip_code  \n",
       "0          65000.0                 0               1  2016-01-01    201xx  \n",
       "1          82400.0                 0               1  2016-01-01    146xx  \n",
       "2         200000.0                 0               3  2016-01-01    208xx  \n",
       "3          85000.0                 0               4  2016-01-01    908xx  \n",
       "4          16800.0                 0               4  2016-01-01    294xx  \n",
       "...            ...               ...             ...         ...      ...  \n",
       "482749     76000.0                 0               1  2018-12-01    483xx  \n",
       "482750     75000.0                 0               4  2018-12-01    917xx  \n",
       "482751     97000.0                 0               4  2018-12-01    801xx  \n",
       "482752     66000.0                 0               3  2018-12-01    452xx  \n",
       "482753     40000.0                 1               4  2018-12-01    117xx  \n",
       "\n",
       "[482754 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = accepted_df.copy()\n",
    "# instantiate a label encoder and transform the categorical features\n",
    "le = LabelEncoder()\n",
    "df['application_type'] = le.fit_transform(df['application_type'])\n",
    "df['term'] = le.fit_transform(df['term'])\n",
    "df['grade'] = le.fit_transform(df['grade'])\n",
    "df['home_ownership'] = le.fit_transform(df['home_ownership'])\n",
    "df['emp_length'] = le.fit_transform(df['emp_length'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and testing set.\n",
    "# I won't be using the date or zip_codes for the training.\n",
    "X = df.drop(['loan_status', 'date', 'zip_code'],axis=1).copy()\n",
    "y = df['loan_status'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# seperate the numerical and categorical columns for training and testing data so that I can scale the numerical\n",
    "# and then concatenate them.\n",
    "# reset the index for smoothe concatenation\n",
    "num_train = X_train.select_dtypes(include='float64').reset_index(drop=True)\n",
    "num_test = X_test.select_dtypes(include='float64').reset_index(drop=True)\n",
    "cat_train = X_train.select_dtypes(include='int32').reset_index(drop=True)\n",
    "cat_test = X_test.select_dtypes(include='int32').reset_index(drop=True)\n",
    "\n",
    "# fit and transform the scaler on training and testing data\n",
    "sc_num_train = sc.fit_transform(num_train)\n",
    "sc_num_test = sc.transform(num_test)\n",
    "# put the scaled data back into a dataframe\n",
    "sc_train_df = pd.DataFrame(sc_num_train, columns=num_train.columns)\n",
    "sc_test_df = pd.DataFrame(sc_num_test, columns=num_test.columns)\n",
    "\n",
    "# concatenate back together\n",
    "X_train_ready = pd.concat([sc_train_df, cat_train], axis=1)\n",
    "X_test_ready = pd.concat([sc_test_df, cat_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a baseline model to compare the rest of our models to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6577871682271385"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
    "dummy.fit(X_train_ready, y_train)\n",
    "plot_confusion_matrix(dummy, X_test_ready, y_test)\n",
    "dummy.score(X_test_ready, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy of Logistic Regression is: 78.41\n",
      "Accuracy of Logistic Regression is: 78.24\n",
      "Recall of Logistic Regression is: 9.91\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate a logistic regression then fit it on X_train and get the scoring metrics witha confusion matrix\n",
    "lr=LogisticRegression(random_state=42)\n",
    "lr.fit(X_train_ready,y_train)\n",
    "train_pred = lr.predict(X_train_ready)\n",
    "lr_pred = lr.predict(X_test_ready)\n",
    "train_accuracy = accuracy_score(y_train, train_pred)*100\n",
    "lr_accuracy= accuracy_score(y_test, lr_pred)*100\n",
    "lr_recall = recall_score(y_test, lr_pred)*100\n",
    "print('Training accuracy of Logistic Regression is: {:.2f}'.format(train_accuracy))\n",
    "print('Accuracy of Logistic Regression is: {:.2f}'.format(lr_accuracy))\n",
    "print('Recall of Logistic Regression is: {:.2f}'.format(lr_recall))\n",
    "plot_confusion_matrix(lr, X_test_ready, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to predict almost 80 percent of the time, should be enough to make you money with this type of investment. However if we're trying to find an edge to get very good value, our model needs to be more sensitive to the defaulted loans. Meaning when our model thinks a loan is safe, we need to be very confident that that's the case. Even if our model tells us that a lot of loans will default when in reality only a few will, if narrow down our investments to the loans the model does not think will default, we get a much better return. So far our model does a very poor job identifying the bad loans. This is largely due to the great imbalance in the classes, which makes it very hard for the model to learn what a defaulted loan would look like.\n",
    "\n",
    "There are 3 ways I can think of to help with this:\n",
    "* Alter the weights of each class to put more weight on the minority class. \n",
    "* Lower the threshhold for predicting a \"1\" to make it more sensitive. \n",
    "* Oversample the minority class with a over-sampling technique like SMOTE to correct the imbalance.\n",
    "\n",
    "Note that the better recall score will probably come at the cost of overall accuaracy.\n",
    "\n",
    "I will try SMOTE first and use a grid search with cross validation to train the model and find the best hyperparameters including the best class weight for overall accuracy. Then on the test data, I will alter the prediction threshold to optimize investment value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance before SMOTE:\n",
      "0    321106\n",
      "1     89234\n",
      "Name: loan_status, dtype: int64\n",
      "\n",
      "Balance after SMOTE:\n",
      "1    321106\n",
      "0    321106\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# instantiate the SMOTE object and fit and sample on the training data.\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_sample(X_train_ready, y_train)\n",
    "# check to see the new balance of classes\n",
    "print('Balance before SMOTE:')\n",
    "print(y_train.value_counts())\n",
    "print('')      \n",
    "print('Balance after SMOTE:')\n",
    "print(y_train_sm.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the grid search on logistic regression \n",
    "def logreg(X_train, y_train, cv=3):\n",
    "    \n",
    "    # Set GridSearchCV hyperparameters to compare & select\n",
    "    grid = {\n",
    "    'max_iter': [75, 100, 150, 200],\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    # because I used smote to fix the imbalance I will give it the option of weighting the paid loans more as well\n",
    "    'class_weight': [{0:2, 1:1}, {0:1, 1:1}, {0:1, 1:3}, {0:1, 1:4}]\n",
    "    }\n",
    "    \n",
    "    # Instantiate & fit LogReg model for GridSearch\n",
    "    grid_logreg = LogisticRegression(random_state=42)\n",
    "    # Instantiate & fit GridSearchCV with accuracy scoring\n",
    "    gs = GridSearchCV(estimator=grid_logreg, param_grid=grid, cv=cv, scoring='accuracy')\n",
    "    gs.fit(X_train, y_train)\n",
    "    # print out the best parameters\n",
    "    params = gs.best_params_\n",
    "    print(\"Best class_weight:\",params['class_weight'])\n",
    "    print(\"Best 'C':\", params['C'])\n",
    "    print(\"Best 'max_iter':\", params['max_iter'])\n",
    "    # instantiate new logistic regression with these parameters\n",
    "    lr = LogisticRegression(max_iter=params['max_iter'], C=params['C'],\n",
    "                            class_weight=params['class_weight'],random_state=42 )\n",
    "    # print the training accuracy\n",
    "    lr.fit(X_train, y_train)\n",
    "    train_pred = knn.predict(X_train)\n",
    "    print('Training accuracy:', round(accuracy_score(y_train, train_pred), 4)*100)\n",
    "    # Run cross-validation using the new logistic regression and print the accuracy and recall\n",
    "    cv_results = cross_validate(lr, X_train, y_train, cv=cv, scoring=['recall', 'accuracy'])\n",
    "    print(f\"Mean Cross-Validation accuracy: {round(cv_results['test_accuracy'].mean(), 4)*100}\")\n",
    "    print(f\"Mean Cross-Validation recall: {round(cv_results['test_recall'].mean(), 4)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best class weight: {0: 1, 1: 1}\n",
      "Best 'C': 0.1\n",
      "Best max_iter: 75\n",
      "Mean Cross-Validation accuracy: 64.48\n",
      "Mean Cross-Validation recall: 61.85000000000001\n"
     ]
    }
   ],
   "source": [
    "cell_start = time.time()\n",
    "logreg(X_train_sm, y_train_sm)\n",
    "print(f'This cell takes {round(time.time() - cell_start, 0)} seconds to run')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using SMOTE the recall went way up which is what we need, and as expected it brought the accuracy down. I will now look at how KNearest Neighbors will perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the grid search on KNearest Neighbors \n",
    "def knn(X_train, y_train, cv=3):\n",
    "    \n",
    "    # Set GridSearchCV hyperparameters to compare & select\n",
    "    param_grid = {\n",
    "    'n_neighbors': [3,5,9,13],\n",
    "    'metric': ['minkowski', 'manhattan'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "    }\n",
    "    \n",
    "    # Instantiate & fit LogReg model for GridSearch\n",
    "    grid_knn = KNeighborsClassifier()\n",
    "    # Instantiate & fit GridSearchCV with accuracy scoring\n",
    "    gs = GridSearchCV(estimator=grid_knn, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "    gs.fit(X_train, y_train)\n",
    "    # print out the best parameters\n",
    "    params = gs.best_params_\n",
    "    print(\"Best 'n_neighbors':\",params['n_neighbors'])\n",
    "    print(\"Best 'metric':\", params['metric'])\n",
    "    print(\"Best 'weights':\", params['weights'])\n",
    "    # instantiate new logistic regression with these parameters\n",
    "    knn = KNeighborsClassifier(n_neighbors=params['n_neighbors'], metric=params['metric'],\n",
    "                            weights=params['weights'])\n",
    "    # print the training score\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_pred = knn.predict(X_train)\n",
    "    print('Training accuracy:', round(accuracy_score(y_train, train_pred), 4)*100)\n",
    "    # Run cross-validation using the new knn and print the accuracy and recall\n",
    "    cv_results = cross_validate(knn, X_train, y_train, cv=cv, scoring=['recall', 'accuracy'])\n",
    "    print(f\"Mean Cross-Validation accuracy: {round(cv_results['test_accuracy'].mean(), 4)*100}\")\n",
    "    print(f\"Mean Cross-Validation recall: {round(cv_results['test_recall'].mean(), 4)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 'n_neighbors': 3\n",
      "Best 'metric': manhattan\n",
      "Best 'weights': distance\n",
      "Training accuracy: 100.0\n",
      "Mean Cross-Validation accuracy: 79.38\n",
      "Mean Cross-Validation recall: 93.01\n",
      "This cell takes 1896.0 seconds to run\n"
     ]
    }
   ],
   "source": [
    "# depending on computer power, this cell can take over a half hour to run.\n",
    "cell_start = time.time()\n",
    "knn(X_train_sm, y_train_sm)\n",
    "print(\"\")\n",
    "print(f'(This cell takes {round(time.time() - cell_start, 0)} seconds to run)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a function for the grid search on random forest to avoid repetitiveness \n",
    "# def random_forest(X_train, y_train, cv=3):\n",
    "    \n",
    "#     # Set GridSearchCV hyperparameters to compare & select\n",
    "#     param_grid = {\n",
    "#     'n_estimators': [100, 125, 150],\n",
    "#     'max_depth':  [15, 25],\n",
    "#     'min_samples_split': [2, 5]\n",
    "#      }\n",
    "\n",
    "    \n",
    "#     # Instantiate & fit LogReg model for GridSearch\n",
    "#     grid_rf = RandomForestClassifier(random_state=42)\n",
    "#     # Instantiate & fit GridSearchCV with accuracy scoring\n",
    "#     gs = GridSearchCV(estimator=grid_rf, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "#     gs.fit(X_train, y_train)\n",
    "#     # print out the best parameters\n",
    "#     params = gs.best_params_\n",
    "#     print(\"Best 'n_estimators':\",params['n_estimators'])\n",
    "#     print(\"Best 'max_depth':\", params['max_depth'])\n",
    "#     print(\"Best 'min_samples_split':\", params['min_samples_split'])\n",
    "#     # instantiate new logistic regression with these parameters\n",
    "#     rf = RandomForestClassifier(n_estimators=params['n_estimators'], max_depth=params['max_depth'], \n",
    "#                                 min_samples_split=params['min_samples_split'], random_state=42 )\n",
    "#     # print the training score\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     train_pred = rf.predict(X_train)\n",
    "#     print('Training accuracy:', round(accuracy_score(y_train, train_pred), 4)*100)\n",
    "#     # Run cross-validation using the new logistic regression\n",
    "#     cv_results = cross_validate(rf, X_train, y_train, cv=cv, scoring=['recall', 'accuracy'])\n",
    "#     print(f\"Mean Cross-Validation accuracy: {round(cv_results['test_accuracy'].mean(), 4)*100}\")\n",
    "#     # Run and print accuracy, recall, precision and f1 scores\n",
    "#     print(f\"Mean Cross-Validation recall: {round(cv_results['test_recall'].mean(), 4)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell_start = time.time()\n",
    "# rf = RandomForestClassifier(random_state=42)\n",
    "# cv = cross_validate(rf, X_train_sm, y_train_sm, cv=3)\n",
    "# cv\n",
    "# print(f'This cell takes {round(time.time() - cell_start, 0)} seconds to run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell_start = time.time()\n",
    "# random_forest(X_train_sm, y_train_sm)\n",
    "# print(\"\")\n",
    "# print(f'(This cell takes {round(time.time() - cell_start, 0)} seconds to run)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to take in to acount that the cross-validation is using data that was oversampled with SMOTE, so the results won't be this good on the test data which still has the imbalance. With that being said, these models should still have good sensitivity on the test data, and in that area KNNis the winner with a 90% sensitivity. With a sensitivity like that, the investor can be confident that very few of the loans the model suggests investing in will default, which means we will almost always be getting the interest from the loan we invest in.\n",
    "\n",
    "I'll now run the model on the testing data, using the hyperparametrs the grid search chose. I will use the predict_proba method so that I can alter the threshold if I want to be more or less conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.51\n",
      "Recall: 48.88\n",
      "F1: 36.5\n"
     ]
    }
   ],
   "source": [
    "# instantiate model and fit on training data\n",
    "final_knn = KNeighborsClassifier(n_neighbors=5, metric='manhattan', weights='distance')\n",
    "final_knn.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# get the predictions and check the accuracy, recall, and f1 scores\n",
    "y_pred = final_knn.predict(X_test_ready)\n",
    "knn_accuracy = accuracy_score(y_test, y_pred)\n",
    "knn_recall = recall_score(y_test, y_pred)\n",
    "knn_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print the metrics out\n",
    "print('Accuracy:', round(knn_accuracy, 4)*100)\n",
    "print('Recall:', round(knn_recall, 4)*100)\n",
    "print('F1:', round(knn_f1, 4)*100)\n",
    "\n",
    "# plot an ROC curve and a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.94\n",
      "Recall: 61.67\n",
      "F1: 44.39\n"
     ]
    }
   ],
   "source": [
    "# instantiate model and fit on training data\n",
    "final_lr = LogisticRegression(max_iter=75, C=0.1, class_weight={0: 1, 1: 1})\n",
    "final_lr.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# get the predictions and check the accuracy, recall, and f1 scores\n",
    "y_pred = final_lr.predict(X_test_ready)\n",
    "lr_accuracy = accuracy_score(y_test, y_pred)\n",
    "lr_recall = recall_score(y_test, y_pred)\n",
    "lr_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print the metrics out\n",
    "print('Accuracy:', round(lr_accuracy, 4)*100)\n",
    "print('Recall:', round(lr_recall, 4)*100)\n",
    "print('F1:', round(lr_f1, 4)*100)\n",
    "\n",
    "# plot an ROC curve and a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned earlier I will try to predict the loans that have higher int_rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_end = time.time()\n",
    "print(f'This notebook takes {round(notebook_end - notebook_start, 0)} seconds to run')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
